{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import mne\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all functions\n",
    "# example 1_al_ciplv_theta_1.npy\n",
    "def parse_filename(filename):\n",
    "    s = filename.split(\"_\")\n",
    "    pId = s[0]\n",
    "    label = s[1]\n",
    "    method = s[2]\n",
    "    freq = s[-2]\n",
    "    epoch = s[-1].split(\".\")[0]\n",
    "    \n",
    "    return {\"pId\": pId, \"label\": label, \"method\": method, \"freq\": freq, \"epoch\": epoch}\n",
    "    # return {\"pId\": pId, \"label\": label, \"method\": method, \"freq\": freq}\n",
    "\n",
    "def read_file(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "# get all the files in the folder output/\n",
    "def get_files(folder, filter = None):\n",
    "    '''\n",
    "    filter is a dictionary, has 2 keys: method and freq to filter the files\n",
    "    '''\n",
    "    files = glob.glob(os.path.join(folder, \"*.npy\"))\n",
    "    ret_files = []\n",
    "    if filter:\n",
    "        for f in files:\n",
    "            # get the filename\n",
    "            filename = os.path.basename(f)\n",
    "            f_info = parse_filename(filename)\n",
    "            # remove epoch 2 if no overlap\n",
    "            if f_info[\"epoch\"] == \"2\":\n",
    "                continue\n",
    "            if (f_info[\"method\"] == filter[\"method\"]) and (f_info[\"freq\"] == filter[\"freq\"]):\n",
    "                ret_files.append(f)\n",
    "    else:\n",
    "        ret_files = files\n",
    "\n",
    "    return ret_files\n",
    "\n",
    "def feature_extraction(data):\n",
    "    \"\"\"\n",
    "    get lower part of diagonal matrix\n",
    "    \"\"\"\n",
    "    data_lower = data[np.tril_indices(data.shape[0], k=-1)]\n",
    "    return data_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging to airtable\n",
    "from airtable.airtable import AirTableClient\n",
    "from airtable.config import config\n",
    "\n",
    "atc = AirTableClient(**config[\"airtable_sensor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "# get the labels for electrodes\n",
    "# fs_dir = mne.datasets.fetch_fsaverage(verbose=True)\n",
    "# subjects_dir = os.path.dirname(fs_dir)\n",
    "# labels = mne.read_labels_from_annot('fsaverage', parc='aparc',\n",
    "#                                     subjects_dir=subjects_dir)\n",
    "# labels.pop(-1)\n",
    "# label_colors = [label.color for label in labels]\n",
    "data_source = \"no_split\"\n",
    "labels = {\"al\": 0, \"fa\":1}\n",
    "\n",
    "methods = ['wpli2']\n",
    "freqs = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "# grid search params for different models\n",
    "models = {\n",
    "    \"svm\": {\n",
    "        \"model\": SVC(kernel='linear', C=1),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"kernel\": ['linear', 'rbf']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(model_name, model, params, X, y):\n",
    "    \"\"\"\n",
    "    run grid search for a model\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(model, params, cv=5, return_train_score=False)\n",
    "    grid_search.fit(X, y)\n",
    "    # print(\"Best params: \", grid_search.best_params_)\n",
    "    # print(\"Best score: \", grid_search.best_score_)\n",
    "    return grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    get the metrics for the model\n",
    "    \"\"\"\n",
    "    full_classification_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    specificity = round(full_classification_report[\"0\"][\"recall\"], 3)\n",
    "    sensitivity = round(full_classification_report[\"1\"][\"recall\"], 3)\n",
    "    accuracy = round(full_classification_report[\"accuracy\"], 3)\n",
    "    \n",
    "    return specificity, sensitivity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: method: wpli2, freq: delta\n",
      "(96, 211)\n",
      "Processing: method: wpli2, freq: delta, model: svm, feature selection: True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72        27\n",
      "           1       0.64      0.76      0.70        21\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.71      0.71      0.71        48\n",
      "weighted avg       0.72      0.71      0.71        48\n",
      "\n",
      "Processing: method: wpli2, freq: theta\n",
      "(96, 208)\n",
      "Processing: method: wpli2, freq: theta, model: svm, feature selection: True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81        27\n",
      "           1       0.71      0.95      0.82        21\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.83      0.83      0.81        48\n",
      "weighted avg       0.85      0.81      0.81        48\n",
      "\n",
      "Processing: method: wpli2, freq: alpha\n",
      "(96, 204)\n",
      "Processing: method: wpli2, freq: alpha, model: svm, feature selection: True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81        27\n",
      "           1       0.74      0.81      0.77        21\n",
      "\n",
      "    accuracy                           0.79        48\n",
      "   macro avg       0.79      0.79      0.79        48\n",
      "weighted avg       0.80      0.79      0.79        48\n",
      "\n",
      "Processing: method: wpli2, freq: beta\n",
      "(96, 212)\n",
      "Processing: method: wpli2, freq: beta, model: svm, feature selection: True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        27\n",
      "           1       0.82      0.86      0.84        21\n",
      "\n",
      "    accuracy                           0.85        48\n",
      "   macro avg       0.85      0.85      0.85        48\n",
      "weighted avg       0.86      0.85      0.85        48\n",
      "\n",
      "Processing: method: wpli2, freq: gamma\n",
      "(96, 219)\n",
      "Processing: method: wpli2, freq: gamma, model: svm, feature selection: True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78        27\n",
      "           1       0.71      0.81      0.76        21\n",
      "\n",
      "    accuracy                           0.77        48\n",
      "   macro avg       0.77      0.78      0.77        48\n",
      "weighted avg       0.78      0.77      0.77        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in methods:\n",
    "    for freq in freqs:\n",
    "        print(\"Processing: method: {}, freq: {}\".format(method, freq))\n",
    "        filter = {\"method\": method, \"freq\": freq}\n",
    "        files = get_files(\"output_sensor/no_split/\", filter)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for f in files:\n",
    "            data = read_file(f)\n",
    "            X.append(feature_extraction(data))\n",
    "            Y.append(labels.get(parse_filename(os.path.basename(f))[\"label\"]))\n",
    "\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "            \n",
    "        # for ifs in [False, True]:\n",
    "        is_feature_selection = True\n",
    "        if is_feature_selection:\n",
    "            lsvc = LinearRegression()\n",
    "            model = SelectFromModel(lsvc)\n",
    "            X_new = model.fit_transform(X, Y)\n",
    "        else:\n",
    "            X_new = X\n",
    "\n",
    "\n",
    "        X_new = np.array(X_new)\n",
    "        Y = np.array(Y)\n",
    "        print(X_new.shape)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size=0.5, random_state=12)\n",
    "        for m in models.keys():\n",
    "            print(\"Processing: method: {}, freq: {}, model: {}, feature selection: {}\".format(method, freq, m, is_feature_selection))\n",
    "            best_params, best_score = run_grid_search(m, models[m][\"model\"], models[m][\"params\"], X_new, Y)\n",
    "            # run best model\n",
    "            model = models[m][\"model\"].set_params(**best_params)\n",
    "            model.fit(X_train, Y_train)\n",
    "            Y_pred = model.predict(X_test)\n",
    "\n",
    "            specificity, sensitivity, accuracy = get_metrics(Y_test, Y_pred)\n",
    "\n",
    "            # print classification report\n",
    "            print(classification_report(Y_test, Y_pred))\n",
    "            \n",
    "            full_classification_report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "            res = {\n",
    "                \"data\": data_source,\n",
    "                \"method\": method,\n",
    "                \"frequency\": freq,\n",
    "                \"model\": m,\n",
    "                \"feature selection\": str(is_feature_selection),\n",
    "                \"best_params\": str(best_params),\n",
    "                \"accuracy\": str(accuracy),\n",
    "                \"specificity\": str(specificity),\n",
    "                \"sensitivity\": str(sensitivity),\n",
    "                \"full accuracy report\": full_classification_report\n",
    "            }\n",
    "            atc.add_row(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('kia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2ef7656957f2cabf33afdcbd2acf1cbe70bf0152c98ddb6dbe8bbc110a41f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
