{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import mne\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all functions\n",
    "# example 1_al_ciplv_theta_1.npy\n",
    "def parse_filename(filename):\n",
    "    s = filename.split(\"_\")\n",
    "    pId = s[0]\n",
    "    label = s[1]\n",
    "    method = s[2]\n",
    "    freq = s[-2]\n",
    "    epoch = s[-1].split(\".\")[0]\n",
    "    \n",
    "    return {\"pId\": pId, \"label\": label, \"method\": method, \"freq\": freq, \"epoch\": epoch}\n",
    "    # return {\"pId\": pId, \"label\": label, \"method\": method, \"freq\": freq}\n",
    "\n",
    "def read_file(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "# get all the files in the folder output/\n",
    "def get_files(folder, filter = None):\n",
    "    '''\n",
    "    filter is a dictionary, has 2 keys: method and freq to filter the files\n",
    "    '''\n",
    "    files = glob.glob(os.path.join(folder, \"*.npy\"))\n",
    "    ret_files = []\n",
    "    if filter:\n",
    "        for f in files:\n",
    "            # get the filename\n",
    "            filename = os.path.basename(f)\n",
    "            f_info = parse_filename(filename)\n",
    "            # remove epoch 2 if no overlap\n",
    "            if f_info[\"epoch\"] == \"2\":\n",
    "                continue\n",
    "            if (f_info[\"method\"] == filter[\"method\"]) and (f_info[\"freq\"] == filter[\"freq\"]):\n",
    "                ret_files.append(f)\n",
    "    else:\n",
    "        ret_files = files\n",
    "\n",
    "    return ret_files\n",
    "\n",
    "def feature_extraction(data):\n",
    "    \"\"\"\n",
    "    get lower part of diagonal matrix\n",
    "    \"\"\"\n",
    "    data_lower = data[np.tril_indices(data.shape[0], k=-1)]\n",
    "    return data_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging to airtable\n",
    "from airtable.airtable import AirTableClient\n",
    "from airtable.config import config\n",
    "\n",
    "atc = AirTableClient(**config[\"airtable_sensor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "# get the labels for electrodes\n",
    "# fs_dir = mne.datasets.fetch_fsaverage(verbose=True)\n",
    "# subjects_dir = os.path.dirname(fs_dir)\n",
    "# labels = mne.read_labels_from_annot('fsaverage', parc='aparc',\n",
    "#                                     subjects_dir=subjects_dir)\n",
    "# labels.pop(-1)\n",
    "# label_colors = [label.color for label in labels]\n",
    "data_source = \"split_10s_overlap_5s\"\n",
    "labels = {\"al\": 0, \"fa\":1}\n",
    "\n",
    "methods = ['pli', 'wpli2', 'ciplv']\n",
    "freqs = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "# grid search params for different models\n",
    "models = {\n",
    "    \"svm\": {\n",
    "        \"model\": SVC(kernel='linear', C=1),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"kernel\": ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    \"logistic\": {\n",
    "        \"model\": LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"solver\": ['liblinear', 'lbfgs']\n",
    "        }\n",
    "    },\n",
    "    # \"QDA\": {\n",
    "    #     \"model\": QuadraticDiscriminantAnalysis(),\n",
    "    #     \"params\": {\n",
    "    #         \"reg_param\": [0.1, 1, 10, 100]\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # \"mlp\": {\n",
    "    #     \"model\": MLPClassifier(),\n",
    "    #     \"params\": {\n",
    "    #         \"hidden_layer_sizes\": [(100, 100), (100,100,100), (100,100,100,100)],\n",
    "    #         \"activation\": ['tanh', 'relu'],\n",
    "    #         \"solver\": ['sgd', 'adam'],\n",
    "    #         \"alpha\": [0.0001, 0.05],\n",
    "    #         \"learning_rate\": ['constant', 'adaptive'],\n",
    "    #     }\n",
    "    # },\n",
    "    # \"random_forest\": {\n",
    "    #     \"model\": RandomForestClassifier(),\n",
    "    #     \"params\": {\n",
    "    #         \"n_estimators\": [100, 200],\n",
    "    #         \"max_features\": ['sqrt', 'log2'],\n",
    "    #         \"max_depth\": [4, 5, 6],\n",
    "    #         \"criterion\": ['gini', 'entropy']\n",
    "    #     }\n",
    "    # },\n",
    "    # \"xgb\": {\n",
    "    #     \"model\": XGBClassifier(),\n",
    "    #     \"params\": {\n",
    "    #         \"learning_rate\": [0.05, 0.1, 0.15],\n",
    "    #         \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    #         \"gamma\": [0.0, 0.1],\n",
    "    #     }\n",
    "    # },\n",
    "    # \"ada\": {\n",
    "    #     \"model\": AdaBoostClassifier(),\n",
    "    #     \"params\": {\n",
    "    #         \"n_estimators\": [50, 100, 200],\n",
    "    #         \"learning_rate\": [0.01, 0.05, 0.1, 0.2]\n",
    "    #     }\n",
    "    # },\n",
    "    \"knn\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "            \"weights\": ['uniform', 'distance'],\n",
    "            \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "    },\n",
    "    # \"decision_tree\": {\n",
    "    #     \"model\": DecisionTreeClassifier(),\n",
    "    #     \"params\": {\n",
    "    #         \"criterion\": [\"gini\", \"entropy\"],\n",
    "    #         \"splitter\": [\"best\", \"random\"],\n",
    "    #         \"max_depth\": [2, 3, 5],\n",
    "    #         \"min_samples_split\": [2, 3, 5],\n",
    "    #         \"min_samples_leaf\": [2, 3, 5]\n",
    "    #     }\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(model_name, model, params, X, y):\n",
    "    \"\"\"\n",
    "    run grid search for a model\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(model, params, cv=5, return_train_score=False)\n",
    "    grid_search.fit(X, y)\n",
    "    # print(\"Best params: \", grid_search.best_params_)\n",
    "    # print(\"Best score: \", grid_search.best_score_)\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    for freq in freqs:\n",
    "        print(\"Processing: method: {}, freq: {}\".format(method, freq))\n",
    "        filter = {\"method\": method, \"freq\": freq}\n",
    "        files = get_files(\"output/split_10s_overlap_5s/\", filter)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for f in files:\n",
    "            data = read_file(f)\n",
    "            X.append(feature_extraction(data))\n",
    "            Y.append(labels.get(parse_filename(os.path.basename(f))[\"label\"]))\n",
    "\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "            \n",
    "        is_feature_selection = True   \n",
    "        # for ifs in [False, True]:\n",
    "        is_feature_selection = True\n",
    "        if is_feature_selection:\n",
    "            lsvc = LinearSVC(C=0.001, penalty=\"l2\", dual=False).fit(X, Y)\n",
    "            model = SelectFromModel(lsvc, prefit=True)\n",
    "            X_new = model.transform(X)\n",
    "        else:\n",
    "            X_new = X\n",
    "\n",
    "        X_new = np.array(X_new)\n",
    "        Y = np.array(Y)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size=0.3, random_state=12)\n",
    "        for m in models.keys():\n",
    "            print(\"Processing: method: {}, freq: {}, model: {}, feature selection: {}\".format(method, freq, m, is_feature_selection))\n",
    "            best_params, best_score = run_grid_search(m, models[m][\"model\"], models[m][\"params\"], X_new, Y)\n",
    "            # run best model\n",
    "            model = models[m][\"model\"].set_params(**best_params)\n",
    "            model.fit(X_train, Y_train)\n",
    "            Y_pred = model.predict(X_test)\n",
    "            score = round(accuracy_score(Y_test, Y_pred),2)\n",
    "            score = round(best_score, 2)\n",
    "            # print classification report\n",
    "            print(classification_report(Y_test, Y_pred))\n",
    "            \n",
    "            full_classification_report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "            res = {\n",
    "                \"data\": data_source,\n",
    "                \"method\": method,\n",
    "                \"frequency\": freq,\n",
    "                \"model\": m,\n",
    "                \"feature selection\": str(is_feature_selection),\n",
    "                \"best_params\": str(best_params),\n",
    "                \"accuracy\": str(score),\n",
    "                \"full accuracy report\": full_classification_report\n",
    "            }\n",
    "            atc.add_row(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('kia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2ef7656957f2cabf33afdcbd2acf1cbe70bf0152c98ddb6dbe8bbc110a41f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
